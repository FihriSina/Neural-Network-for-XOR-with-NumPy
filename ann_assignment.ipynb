{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3925e79f",
   "metadata": {},
   "source": [
    "1.  Kitaplıklar ve Veri Seti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4e3ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# XOR Veri Seti\n",
    "X = np.array([[0, 0],\n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "\n",
    "# Beklenen çıktı (target)\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# Öğrenme oranı\n",
    "learning_rate = 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0b5d83",
   "metadata": {},
   "source": [
    "        - İleri Yayılım (Forward Propagation) Nedir?\n",
    "\n",
    "    Giriş verileri alınır.\n",
    "    Giriş katmanından gizli katmana doğru hesaplamalar yapılır.\n",
    "    Gizli katmandan çıkış katmanına geçilir.\n",
    "    Çıktılar (tahmin edilen değerler) elde edilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddc9236",
   "metadata": {},
   "source": [
    "    Giriş: x1, x2\n",
    "    Ağırlıklar: w1, w2\n",
    "    Bias: b\n",
    "    Çıktı = sigmoid(w1*x1 + w2*x2 + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c668ee04",
   "metadata": {},
   "source": [
    "2. Ağırlık ve Bias’ların Başlatılması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c14e3b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rastgele ağırlık ve bias başlat (küçük değerlerle)\n",
    "np.random.seed(42)  # Aynı sonuçları almak için sabit tohum\n",
    "\n",
    "# Giriş -> Gizli (2 giriş, 2 gizli nöron)\n",
    "weights_input_hidden = np.random.uniform(-1, 1, (2, 2)) # weights_input_hidden: Girişten gizli katmana olan bağlantıların ağırlıkları\n",
    "bias_hidden = np.random.uniform(-1, 1, (1, 2))          # bias_hidden: Gizli katmandaki her nöron için bir bias\n",
    "\n",
    "# Gizli -> Çıkış (2 gizli, 1 çıkış)\n",
    "weights_hidden_output = np.random.uniform(-1, 1, (2, 1))# weights_hidden_output: Gizli katmandan çıkışa olan bağlantı ağırlıkları\n",
    "bias_output = np.random.uniform(-1, 1, (1, 1))          # bias_output: Çıkış katmanındaki nöron için bir bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda9ce08",
   "metadata": {},
   "source": [
    "3. Aktivasyon Fonksiyonu: Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a42eda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid fonksiyonu\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Sigmoid'in türevi (geri yayılımda lazım olacak)\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c25fec",
   "metadata": {},
   "source": [
    "4. İleri Yayılım Fonksiyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8287482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X):\n",
    "    # Giriş -> Gizli\n",
    "    z1 = np.dot(X, weights_input_hidden) + bias_hidden  # net input\n",
    "    a1 = sigmoid(z1)  # aktivasyon\n",
    "\n",
    "    # Gizli -> Çıkış\n",
    "    z2 = np.dot(a1, weights_hidden_output) + bias_output  # net input\n",
    "    a2 = sigmoid(z2)  # tahmin edilen çıktı\n",
    "\n",
    "    return a1, a2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee0a6dd",
   "metadata": {},
   "source": [
    "5. İlk Tahminleri Görelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "096f27f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tahmin Edilen Çıktılar:\n",
      " [[0.53781614]\n",
      " [0.52190923]\n",
      " [0.58876548]\n",
      " [0.57533552]]\n"
     ]
    }
   ],
   "source": [
    "a1, output = forward_propagation(X)\n",
    "print(\"Tahmin Edilen Çıktılar:\\n\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276208bb",
   "metadata": {},
   "source": [
    "![alt text](<Data Mining için Görüntü.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0252a88d",
   "metadata": {},
   "source": [
    "        - Geri Yayılım (Backpropagation) Nedir?\n",
    "\n",
    "    Çıkıştaki hatayı hesapla (gerçek değer - tahmin).\n",
    "    Sigmoid fonksiyonunun türevini uygula.\n",
    "    Bu hatayı gizli katmana yay.\n",
    "    Ağırlıkları ve biasları güncelle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090cfaa0",
   "metadata": {},
   "source": [
    "6. Geri Yayılım Fonksiyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76ec1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(X, y, a1, a2):\n",
    "    global weights_input_hidden, weights_hidden_output, bias_hidden, bias_output\n",
    "\n",
    "    # 1. Çıkış katmanındaki hata\n",
    "    error_output = y - a2 # error_output = y - a2: Modelin tahmin hatası.\n",
    "    delta_output = error_output * sigmoid_derivative(a2) # delta_output: Hatanın sigmoid türeviyle çarpılması\n",
    "\n",
    "    # 2. Gizli katmandaki hata\n",
    "    error_hidden = delta_output.dot(weights_hidden_output.T)\n",
    "    delta_hidden = error_hidden * sigmoid_derivative(a1)\n",
    "\n",
    "    # 3. Ağırlık ve bias güncellemeleri\n",
    "    weights_hidden_output += a1.T.dot(delta_output) * learning_rate\n",
    "    bias_output += np.sum(delta_output, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "    weights_input_hidden += X.T.dot(delta_hidden) * learning_rate\n",
    "    bias_hidden += np.sum(delta_hidden, axis=0, keepdims=True) * learning_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1081d46c",
   "metadata": {},
   "source": [
    "7. Eğitim Döngüsü (Training Loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aa357ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Kayıp (Loss): 0.2544854461282151\n",
      "Epoch 1000 - Kayıp (Loss): 0.25000444851288384\n",
      "Epoch 2000 - Kayıp (Loss): 0.2493089160137819\n",
      "Epoch 3000 - Kayıp (Loss): 0.24222107913692376\n",
      "Epoch 4000 - Kayıp (Loss): 0.17394540094702698\n",
      "Epoch 5000 - Kayıp (Loss): 0.048030749544116506\n",
      "Epoch 6000 - Kayıp (Loss): 0.016497946486187656\n",
      "Epoch 7000 - Kayıp (Loss): 0.008891417670946334\n",
      "Epoch 8000 - Kayıp (Loss): 0.005873938000835527\n",
      "Epoch 9000 - Kayıp (Loss): 0.004317806837677289\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10000):\n",
    "    a1, a2 = forward_propagation(X)\n",
    "    backpropagation(X, y, a1, a2)\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        loss = np.mean((y - a2) ** 2)\n",
    "        print(f\"Epoch {epoch} - Kayıp (Loss): {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18592b6",
   "metadata": {},
   "source": [
    "8. Eğitim Sonrası Tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a955bcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eğitilmiş Modelin Tahminleri:\n",
      " [[0.06163868]\n",
      " [0.94418828]\n",
      " [0.94420396]\n",
      " [0.05927355]]\n"
     ]
    }
   ],
   "source": [
    "_, trained_output = forward_propagation(X)\n",
    "print(\"Eğitilmiş Modelin Tahminleri:\\n\", trained_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
